{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ROG\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from boruta import boruta_py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of nulls on pandas dataframe\n",
    "def val_pd_df_nan(df):\n",
    "    flat_data = df.values.flatten()\n",
    "    count=0\n",
    "    for value in flat_data:\n",
    "        if value is not None:\n",
    "            continue\n",
    "        count+= 1\n",
    "    return round(100*count/len(flat_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (16000,)\n",
      "(60000, 170) (16000, 170)\n"
     ]
    }
   ],
   "source": [
    "train_ds = pd.read_csv('data/aps_failure_training_set_processed_8bit.csv', na_values='na')\n",
    "test_ds =  pd.read_csv('data/aps_failure_test_set_processed_8bit.csv', na_values='na')\n",
    "\n",
    "train_labels = train_ds['class']\n",
    "test_labels = test_ds['class']\n",
    "train_features = train_ds.drop('class', axis=1)\n",
    "test_features = test_ds.drop('class', axis=1)\n",
    "\n",
    "print(train_labels.shape, test_labels.shape)\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(round)\n",
    "train_labels = train_labels.replace({-1:0})\n",
    "\n",
    "test_labels = test_labels.apply(round)\n",
    "test_labels = test_labels.replace({-1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion balanced: 1/1\n",
      "1    1000\n",
      "0    1000\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "number_samples = 1000\n",
    "\n",
    "idxs_pos = train_labels[train_labels==1].index\n",
    "idxs_neg = train_labels[train_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "train_features_balanced = train_features.loc[idxs_balanced]\n",
    "train_labels_balanced = train_labels.loc[idxs_balanced]\n",
    "print(f'Proportion balanced: {int(number_samples/1000)}/1')\n",
    "print(train_labels_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = 375\n",
    "\n",
    "# idxs_pos = test_labels[test_labels==1].index\n",
    "# idxs_neg = test_labels[test_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "# idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "# test_features_balanced = test_features.loc[idxs_balanced]\n",
    "# test_labels_balanced = test_labels.loc[idxs_balanced]\n",
    "# print(f'Proportion balanced: {int(number_samples/1000)}/1')\n",
    "# print(test_labels_balanced.value_counts())\n",
    "\n",
    "test_features_balanced = test_features\n",
    "test_labels_balanced = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_features_balanced)\n",
    "\n",
    "joblib.dump(scaler, \"models/MinMaxScaler.save\") \n",
    "scaler = joblib.load(\"models/MinMaxScaler.save\") \n",
    "\n",
    "train_features_balanced = pd.DataFrame(scaler.transform(train_features_balanced), columns=train_features_balanced.columns)\n",
    "test_features_balanced = pd.DataFrame(scaler.transform(test_features_balanced), columns=test_features_balanced.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectKBest = SelectKBest(chi2, 88)\n",
    "\n",
    "pca = PCA(0.95)\n",
    "\n",
    "borutaSelector = boruta_py.BorutaPy(\n",
    "    RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5), \n",
    "    n_estimators='auto', \n",
    "    verbose=0, \n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# estimators pipeline\n",
    "rf_pipeline = Pipeline([('rf', rf)])\n",
    "kbest_pipeline = Pipeline([('selectKBest', selectKBest), ('rf', rf)])\n",
    "pca_pipeline = Pipeline([('pca', pca), ('rf', rf)])\n",
    "boruta_pipeline = Pipeline([('borutaSelector', borutaSelector), ('rf', rf)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KBest + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1000\n",
      "           1       0.96      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     15625\n",
      "           1       0.28      0.98      0.44       375\n",
      "\n",
      "    accuracy                           0.94     16000\n",
      "   macro avg       0.64      0.96      0.70     16000\n",
      "weighted avg       0.98      0.94      0.96     16000\n",
      "\n",
      "      tn   fp  fn   tp\n",
      "0  14679  946   6  369\n",
      "Total cost is:12460.0\n"
     ]
    }
   ],
   "source": [
    "kbest_pipeline.fit(train_features_balanced, train_labels_balanced)\n",
    "\n",
    "# train\n",
    "y_pred = kbest_pipeline.predict(train_features_balanced)\n",
    "report = classification_report(train_labels_balanced, y_pred)\n",
    "print(report)\n",
    "\n",
    "# test\n",
    "y_pred = kbest_pipeline.predict(test_features_balanced)\n",
    "report = classification_report(test_labels_balanced, y_pred)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(test_labels_balanced, y_pred).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "print(cm)\n",
    "\n",
    "total_cost = 10*cm.fp + 500*cm.fn\n",
    "print(f'Total cost is:{float(total_cost.values[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns count: 170\n",
      "columns count after kbest: 88\n",
      "columns selected: ['aa_000' 'ag_001' 'ag_002' 'ag_003' 'ag_004' 'ag_005' 'ag_006' 'ah_000'\n",
      " 'ai_000' 'al_000' 'am_0' 'an_000' 'ao_000' 'ap_000' 'aq_000' 'ay_007'\n",
      " 'ay_008' 'az_000' 'az_001' 'az_002' 'az_004' 'az_005' 'ba_000' 'ba_001'\n",
      " 'ba_002' 'ba_003' 'ba_004' 'ba_005' 'ba_006' 'ba_007' 'ba_008' 'ba_009'\n",
      " 'bb_000' 'bc_000' 'bd_000' 'be_000' 'bf_000' 'bg_000' 'bh_000' 'bi_000'\n",
      " 'bj_000' 'bt_000' 'bu_000' 'bv_000' 'bx_000' 'by_000' 'cc_000' 'ci_000'\n",
      " 'cj_000' 'ck_000' 'cl_000' 'cm_000' 'cn_000' 'cn_001' 'cn_002' 'cn_003'\n",
      " 'cn_004' 'cn_005' 'cn_006' 'cn_007' 'cn_008' 'cq_000' 'cs_000' 'cs_001'\n",
      " 'cs_002' 'cs_003' 'cs_004' 'cs_005' 'cu_000' 'cv_000' 'cx_000' 'dc_000'\n",
      " 'dd_000' 'de_000' 'dn_000' 'ds_000' 'dt_000' 'eb_000' 'ec_00' 'ed_000'\n",
      " 'ee_000' 'ee_001' 'ee_002' 'ee_003' 'ee_004' 'ee_005' 'ee_006' 'ee_007']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns count:\", len(train_features_balanced.columns))\n",
    "print(\"columns count after kbest:\", len(train_features_balanced.columns[kbest_pipeline[0].get_support()]))\n",
    "print(\"columns selected:\", train_features_balanced.columns[kbest_pipeline[0].get_support()].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1000\n",
      "           1       0.94      0.98      0.96      1000\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.96      0.96      0.96      2000\n",
      "weighted avg       0.96      0.96      0.96      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     15625\n",
      "           1       0.21      0.99      0.35       375\n",
      "\n",
      "    accuracy                           0.91     16000\n",
      "   macro avg       0.61      0.95      0.65     16000\n",
      "weighted avg       0.98      0.91      0.94     16000\n",
      "\n",
      "      tn    fp  fn   tp\n",
      "0  14243  1382   5  370\n",
      "Total cost is:16320.0\n"
     ]
    }
   ],
   "source": [
    "pca_pipeline.fit(train_features_balanced, train_labels_balanced)\n",
    "\n",
    "# train\n",
    "y_pred = pca_pipeline.predict(train_features_balanced)\n",
    "report = classification_report(train_labels_balanced, y_pred)\n",
    "print(report)\n",
    "\n",
    "# test\n",
    "y_pred = pca_pipeline.predict(test_features_balanced)\n",
    "report = classification_report(test_labels_balanced, y_pred)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(test_labels_balanced, y_pred).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "print(cm)\n",
    "\n",
    "total_cost = 10*cm.fp + 500*cm.fn\n",
    "print(f'Total cost is:{float(total_cost.values[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns count: 170\n",
      "pca components: 50\n"
     ]
    }
   ],
   "source": [
    "print(\"columns count:\", len(train_features_balanced.columns))\n",
    "print(\"pca components:\", pca_pipeline[0].n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      1000\n",
      "           1       0.96      0.98      0.97      1000\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     15625\n",
      "           1       0.28      0.98      0.44       375\n",
      "\n",
      "    accuracy                           0.94     16000\n",
      "   macro avg       0.64      0.96      0.70     16000\n",
      "weighted avg       0.98      0.94      0.96     16000\n",
      "\n",
      "      tn   fp  fn   tp\n",
      "0  14680  945   7  368\n",
      "Total cost is:12950.0\n"
     ]
    }
   ],
   "source": [
    "boruta_pipeline.fit(train_features_balanced.values, train_labels_balanced.values)\n",
    "\n",
    "joblib.dump(boruta_pipeline, \"models/boruta_pipeline.save\") \n",
    "boruta_pipeline = joblib.load(\"models/boruta_pipeline.save\") \n",
    "\n",
    "# train\n",
    "y_pred = boruta_pipeline.predict(train_features_balanced.values)\n",
    "report = classification_report(train_labels_balanced, y_pred)\n",
    "print(report)\n",
    "\n",
    "# test\n",
    "y_pred = boruta_pipeline.predict(test_features_balanced.values)\n",
    "report = classification_report(test_labels_balanced, y_pred)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(test_labels_balanced, y_pred).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "print(cm)\n",
    "\n",
    "total_cost = 10*cm.fp + 500*cm.fn\n",
    "print(f'Total cost is:{float(total_cost.values[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns count: 170\n",
      "columns count after boruta: 91\n",
      "columns selected: ['aa_000' 'ag_001' 'ag_002' 'ag_003' 'ag_004' 'ag_005' 'ag_006' 'ah_000'\n",
      " 'ai_000' 'al_000' 'am_0' 'an_000' 'ao_000' 'ap_000' 'aq_000' 'ay_006'\n",
      " 'ay_007' 'ay_008' 'az_000' 'az_001' 'az_002' 'az_005' 'ba_000' 'ba_001'\n",
      " 'ba_002' 'ba_003' 'ba_004' 'ba_005' 'ba_006' 'ba_008' 'ba_009' 'bb_000'\n",
      " 'bc_000' 'bd_000' 'be_000' 'bg_000' 'bh_000' 'bi_000' 'bj_000' 'bk_000'\n",
      " 'bl_000' 'bm_000' 'bn_000' 'bo_000' 'bp_000' 'bq_000' 'br_000' 'bs_000'\n",
      " 'bt_000' 'bu_000' 'bv_000' 'bx_000' 'by_000' 'cc_000' 'cg_000' 'ci_000'\n",
      " 'cj_000' 'ck_000' 'cm_000' 'cn_000' 'cn_001' 'cn_002' 'cn_003' 'cn_004'\n",
      " 'cn_005' 'cn_007' 'cn_008' 'cn_009' 'cq_000' 'cs_000' 'cs_001' 'cs_002'\n",
      " 'cs_003' 'cs_004' 'cs_005' 'cx_000' 'dd_000' 'de_000' 'dn_000' 'ds_000'\n",
      " 'dt_000' 'ec_00' 'ed_000' 'ee_000' 'ee_001' 'ee_002' 'ee_003' 'ee_004'\n",
      " 'ee_005' 'ee_006' 'ee_007']\n"
     ]
    }
   ],
   "source": [
    "print(\"columns count:\", len(train_features_balanced.columns))\n",
    "print(\"columns count after boruta:\", len(train_features_balanced.columns[boruta_pipeline[0].support_]))\n",
    "print(\"columns selected:\", train_features_balanced.columns[boruta_pipeline[0].support_].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97      1000\n",
      "           1       0.96      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.97      2000\n",
      "   macro avg       0.97      0.97      0.97      2000\n",
      "weighted avg       0.97      0.97      0.97      2000\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     15625\n",
      "           1       0.28      0.98      0.43       375\n",
      "\n",
      "    accuracy                           0.94     16000\n",
      "   macro avg       0.64      0.96      0.70     16000\n",
      "weighted avg       0.98      0.94      0.96     16000\n",
      "\n",
      "      tn   fp  fn   tp\n",
      "0  14656  969   7  368\n",
      "Total cost is:13190.0\n"
     ]
    }
   ],
   "source": [
    "rf_pipeline.fit(train_features_balanced, train_labels_balanced)\n",
    "\n",
    "# train\n",
    "y_pred = rf_pipeline.predict(train_features_balanced)\n",
    "report = classification_report(train_labels_balanced, y_pred)\n",
    "print(report)\n",
    "\n",
    "# test\n",
    "y_pred = rf_pipeline.predict(test_features_balanced)\n",
    "report = classification_report(test_labels_balanced, y_pred)\n",
    "print(report)\n",
    "\n",
    "cm = confusion_matrix(test_labels_balanced, y_pred).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "print(cm)\n",
    "\n",
    "total_cost = 10*cm.fp + 500*cm.fn\n",
    "print(f'Total cost is:{float(total_cost.values[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
