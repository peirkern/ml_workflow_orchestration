{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import random\n",
    "# import tempfile\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import *\n",
    "\n",
    "from boruta import boruta_py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of nulls on pandas dataframe\n",
    "def val_pd_df_nan(df):\n",
    "    flat_data = df.values.flatten()\n",
    "    count=0\n",
    "    for value in flat_data:\n",
    "        if value is not None:\n",
    "            continue\n",
    "        count+= 1\n",
    "    return round(100*count/len(flat_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (16000,)\n",
      "(60000, 170) (16000, 170)\n"
     ]
    }
   ],
   "source": [
    "train_ds = pd.read_csv('data/aps_failure_training_set_processed_8bit.csv', na_values='na')\n",
    "test_ds =  pd.read_csv('data/aps_failure_test_set_processed_8bit.csv', na_values='na')\n",
    "\n",
    "train_labels = train_ds['class']\n",
    "test_labels = test_ds['class']\n",
    "train_features = train_ds.drop('class', axis=1)\n",
    "test_features = test_ds.drop('class', axis=1)\n",
    "\n",
    "print(train_labels.shape, test_labels.shape)\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(round)\n",
    "train_labels = train_labels.replace({-1:0})\n",
    "\n",
    "test_labels = test_labels.apply(round)\n",
    "test_labels = test_labels.replace({-1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion balanced: 1/1\n",
      "1    1000\n",
      "0    1000\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "number_samples = 1000\n",
    "\n",
    "idxs_pos = train_labels[train_labels==1].index\n",
    "idxs_neg = train_labels[train_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "train_features_balanced = train_features.loc[idxs_balanced]\n",
    "train_labels_balanced = train_labels.loc[idxs_balanced]\n",
    "print(f'Proportion balanced: {int(number_samples/1000)}/1')\n",
    "print(train_labels_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = 375\n",
    "\n",
    "# idxs_pos = test_labels[test_labels==1].index\n",
    "# idxs_neg = test_labels[test_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "# idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "# test_features_balanced = test_features.loc[idxs_balanced]\n",
    "# test_labels_balanced = test_labels.loc[idxs_balanced]\n",
    "# print(f'Proportion balanced: {int(number_samples/1000)}/1')\n",
    "# print(test_labels_balanced.value_counts())\n",
    "\n",
    "test_features_balanced = test_features\n",
    "test_labels_balanced = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_features_balanced)\n",
    "\n",
    "# # model export\n",
    "# joblib.dump(scaler, \"models/MinMaxScaler.save\") \n",
    "# scaler = joblib.load(\"models/MinMaxScaler.save\") \n",
    "\n",
    "train_features_balanced = pd.DataFrame(scaler.transform(train_features_balanced), columns=train_features_balanced.columns)\n",
    "test_features_balanced = pd.DataFrame(scaler.transform(test_features_balanced), columns=test_features_balanced.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running C:\\Users\\ROG\\anaconda3\\envs\\mlworkflow\\lib\\site-packages\\ipykernel_launcher.py with tracking URI http://192.168.99.100:5000\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://192.168.99.100:5000\")\n",
    "mlflow.set_experiment(\"demo_ml\")\n",
    "print(\"Running {} with tracking URI {}\".format(sys.argv[0], mlflow.get_tracking_uri()))\n",
    "\n",
    "def ml_tracking(params, metrics, models):\n",
    "    with mlflow.start_run():\n",
    "        # log params\n",
    "        for param, value in params.items():\n",
    "            mlflow.log_param(param, value)\n",
    "        # log metrics\n",
    "        for metric, value in metrics.items():\n",
    "            mlflow.log_metric(metric, value)\n",
    "        # log models\n",
    "        for key, model in models.items():\n",
    "            mlflow.sklearn.log_model(model, key)\n",
    "#         run_id = mlflow.active_run().info.run_id\n",
    "#         service = mlflow.tracking.MlflowClient()\n",
    "#         run = service.get_run(run_id)\n",
    "#         print(\"Metadata & data for run with UUID %s: %s\" % (run_id, run))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectKBest = SelectKBest(chi2, 88)\n",
    "pca = PCA(0.95)\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "borutaSelector = boruta_py.BorutaPy(rf, n_estimators='auto', verbose=0, random_state=123)\n",
    "\n",
    "# training and validation template\n",
    "def run(pipeline, train_X, train_y, test_X, test_y, fit_predict_arr=False):\n",
    "    \n",
    "    # train\n",
    "    pipeline.fit(train_X.values, train_y.values) if fit_predict_arr else pipeline.fit(train_X, train_y)\n",
    "    \n",
    "    # predict train\n",
    "    y_pred = pipeline.predict(train_X.values) if fit_predict_arr else pipeline.predict(train_X)\n",
    "    train_report = classification_report(train_y, y_pred)\n",
    "    # print(train_report)\n",
    "    \n",
    "    # predict test\n",
    "    y_pred = pipeline.predict(test_X.values) if fit_predict_arr else pipeline.predict(test_X)\n",
    "    test_report = classification_report(test_y, y_pred)\n",
    "    print(test_report)\n",
    "    \n",
    "    # generate confusion matrix\n",
    "    cm = confusion_matrix(test_y, y_pred).ravel()\n",
    "    cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "    print(cm)\n",
    "    \n",
    "    # generate cost\n",
    "    total_cost = 10 * cm.fp + 500 * cm.fn\n",
    "    print(f'Total cost is:{float(total_cost.values[0])}')\n",
    "    \n",
    "    # mlflow tracking\n",
    "    ml_tracking(\n",
    "        params={}, \n",
    "        metrics={\n",
    "            \"cost\": float(total_cost),\n",
    "            \"weighted_f1\": f1_score(test_y, y_pred, average='weighted'),\n",
    "            \"accuracy_score\": accuracy_score(test_y, y_pred)\n",
    "        }, \n",
    "        models={\n",
    "            \"MinMaxScaler\": scaler,\n",
    "            \"Pipeline\": pipeline\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KBest + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     15625\n",
      "           1       0.28      0.98      0.44       375\n",
      "\n",
      "    accuracy                           0.94     16000\n",
      "   macro avg       0.64      0.96      0.70     16000\n",
      "weighted avg       0.98      0.94      0.96     16000\n",
      "\n",
      "      tn   fp  fn   tp\n",
      "0  14700  925   8  367\n",
      "Total cost is:13250.0\n",
      "features count: 170\n",
      "features count after kbest: 88\n",
      "features selected: ['aa_000' 'ag_001' 'ag_002' 'ag_003' 'ag_004' 'ag_005' 'ag_006' 'ah_000'\n",
      " 'ai_000' 'al_000' 'am_0' 'an_000' 'ao_000' 'ap_000' 'aq_000' 'ay_007'\n",
      " 'ay_008' 'az_000' 'az_001' 'az_002' 'az_004' 'az_005' 'ba_000' 'ba_001'\n",
      " 'ba_002' 'ba_003' 'ba_004' 'ba_005' 'ba_006' 'ba_007' 'ba_008' 'ba_009'\n",
      " 'bb_000' 'bc_000' 'bd_000' 'be_000' 'bf_000' 'bg_000' 'bh_000' 'bi_000'\n",
      " 'bj_000' 'bt_000' 'bu_000' 'bv_000' 'bx_000' 'by_000' 'cc_000' 'ci_000'\n",
      " 'cj_000' 'ck_000' 'cl_000' 'cm_000' 'cn_000' 'cn_001' 'cn_002' 'cn_003'\n",
      " 'cn_004' 'cn_005' 'cn_006' 'cn_007' 'cn_008' 'cq_000' 'cs_000' 'cs_001'\n",
      " 'cs_002' 'cs_003' 'cs_004' 'cs_005' 'cu_000' 'cv_000' 'cx_000' 'dc_000'\n",
      " 'dd_000' 'de_000' 'dn_000' 'ds_000' 'dt_000' 'eb_000' 'ec_00' 'ed_000'\n",
      " 'ee_000' 'ee_001' 'ee_002' 'ee_003' 'ee_004' 'ee_005' 'ee_006' 'ee_007']\n"
     ]
    }
   ],
   "source": [
    "# kbest + rf pipeline\n",
    "kbest_pipeline = Pipeline([('selectKBest', selectKBest), ('rf', rf)])\n",
    "\n",
    "# execute training and validation\n",
    "run(kbest_pipeline, train_features_balanced, train_labels_balanced, test_features_balanced, test_labels_balanced)\n",
    "\n",
    "print(\"features count:\", len(train_features_balanced.columns))\n",
    "print(\"features count after kbest:\", len(train_features_balanced.columns[kbest_pipeline[0].get_support()]))\n",
    "print(\"features selected:\", train_features_balanced.columns[kbest_pipeline[0].get_support()].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     15625\n",
      "           1       0.21      0.99      0.35       375\n",
      "\n",
      "    accuracy                           0.91     16000\n",
      "   macro avg       0.61      0.95      0.65     16000\n",
      "weighted avg       0.98      0.91      0.94     16000\n",
      "\n",
      "      tn    fp  fn   tp\n",
      "0  14263  1362   4  371\n",
      "Total cost is:15620.0\n",
      "features count: 170\n",
      "pca components: 50\n"
     ]
    }
   ],
   "source": [
    "# pca + rf pipeline\n",
    "pca_pipeline = Pipeline([('pca', pca), ('rf', rf)])\n",
    "\n",
    "# execute training and validation\n",
    "run(pca_pipeline, train_features_balanced, train_labels_balanced, test_features_balanced, test_labels_balanced)\n",
    "\n",
    "print(\"features count:\", len(train_features_balanced.columns))\n",
    "print(\"pca components:\", pca_pipeline[0].n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     15625\n",
      "           1       0.29      0.98      0.44       375\n",
      "\n",
      "    accuracy                           0.94     16000\n",
      "   macro avg       0.64      0.96      0.71     16000\n",
      "weighted avg       0.98      0.94      0.96     16000\n",
      "\n",
      "      tn   fp  fn   tp\n",
      "0  14705  920   8  367\n",
      "Total cost is:13200.0\n",
      "features count: 170\n",
      "features count after boruta: 91\n",
      "features selected: ['aa_000' 'ag_001' 'ag_002' 'ag_003' 'ag_004' 'ag_005' 'ag_006' 'ah_000'\n",
      " 'ai_000' 'al_000' 'am_0' 'an_000' 'ao_000' 'ap_000' 'aq_000' 'ay_006'\n",
      " 'ay_007' 'ay_008' 'az_000' 'az_001' 'az_002' 'az_005' 'ba_000' 'ba_001'\n",
      " 'ba_002' 'ba_003' 'ba_004' 'ba_005' 'ba_006' 'ba_008' 'ba_009' 'bb_000'\n",
      " 'bc_000' 'bd_000' 'be_000' 'bg_000' 'bh_000' 'bi_000' 'bj_000' 'bk_000'\n",
      " 'bl_000' 'bm_000' 'bn_000' 'bo_000' 'bp_000' 'bq_000' 'br_000' 'bs_000'\n",
      " 'bt_000' 'bu_000' 'bv_000' 'bx_000' 'by_000' 'cc_000' 'cg_000' 'ci_000'\n",
      " 'cj_000' 'ck_000' 'cm_000' 'cn_000' 'cn_001' 'cn_002' 'cn_003' 'cn_004'\n",
      " 'cn_005' 'cn_007' 'cn_008' 'cn_009' 'cq_000' 'cs_000' 'cs_001' 'cs_002'\n",
      " 'cs_003' 'cs_004' 'cs_005' 'cx_000' 'dd_000' 'de_000' 'dn_000' 'ds_000'\n",
      " 'dt_000' 'ec_00' 'ed_000' 'ee_000' 'ee_001' 'ee_002' 'ee_003' 'ee_004'\n",
      " 'ee_005' 'ee_006' 'ee_007']\n"
     ]
    }
   ],
   "source": [
    "# boruta + rf pipeline\n",
    "boruta_pipeline = Pipeline([('borutaSelector', borutaSelector), ('rf', rf)])\n",
    "\n",
    "# execute training and validation\n",
    "run(boruta_pipeline, train_features_balanced, train_labels_balanced, test_features_balanced, test_labels_balanced, True)\n",
    "\n",
    "print(\"features count:\", len(train_features_balanced.columns))\n",
    "print(\"features count after boruta:\", len(train_features_balanced.columns[boruta_pipeline[0].support_]))\n",
    "print(\"features selected:\", train_features_balanced.columns[boruta_pipeline[0].support_].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     15625\n",
      "           1       0.28      0.98      0.44       375\n",
      "\n",
      "    accuracy                           0.94     16000\n",
      "   macro avg       0.64      0.96      0.70     16000\n",
      "weighted avg       0.98      0.94      0.96     16000\n",
      "\n",
      "      tn   fp  fn   tp\n",
      "0  14685  940   6  369\n",
      "Total cost is:12400.0\n"
     ]
    }
   ],
   "source": [
    "# rf pipeline\n",
    "rf_pipeline = Pipeline([('rf', rf)])\n",
    "\n",
    "# execute training and validation\n",
    "run(rf_pipeline, train_features_balanced, train_labels_balanced, test_features_balanced, test_labels_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
