{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "\n",
    "url = 'https://archive.org/download/datasets_202003/aps-failure-at-scania-trucks-data-set.zip'\n",
    "content = requests.get(url)\n",
    "\n",
    "# unzip the content\n",
    "f = ZipFile(BytesIO(content.content))\n",
    "f.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of nulls on pandas dataframe\n",
    "def val_pd_df_nan(df):\n",
    "    flat_data = df.values.flatten()\n",
    "    count=0\n",
    "    for value in flat_data:\n",
    "        if value is not None:\n",
    "            continue\n",
    "        count+= 1\n",
    "    return round(100*count/len(flat_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The training set contains 60000 examples in total in which 59000 belong to the negative class and 1000 positive class. The test set contains 16000 examples. There are 171 attributes per record.\n",
    "\n",
    "The attribute names of the data have been anonymized for proprietary reasons. It consists of both single numerical counters and histograms consisting of bins with different conditions. Typically the histograms have open-ended conditions at each end. For example, if we measuring the ambient temperature \"T\" then the histogram could be defined with 4 bins where:\n",
    "\n",
    "The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like \"Identifier_Bin\". In total there are 171 attributes, of which 7 are histogram variables. Missing values are denoted by \"na\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd.read_csv('data/aps_failure_training_set_processed_8bit.csv', na_values='na')\n",
    "test_ds =  pd.read_csv('data/aps_failure_test_set_processed_8bit.csv', na_values='na')\n",
    "\n",
    "train_labels = train_ds['class']\n",
    "test_labels = test_ds['class']\n",
    "train_features = train_ds.drop('class', axis=1)\n",
    "test_features = test_ds.drop('class', axis=1)\n",
    "\n",
    "print(train_labels.shape, test_labels.shape)\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{val_pd_df_nan(train_features)}% of train data are non-valid.')\n",
    "print(f'{val_pd_df_nan(test_features)}% of test data are non-valid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_features)\n",
    "train_features = pd.DataFrame(scaler.transform(train_features), columns=train_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(round)\n",
    "train_labels = train_labels.replace({-1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# corr_matrix = train_features.corr()\n",
    "# ax = sns.heatmap(corr_matrix, square=True, cmap='Purples', ax=ax)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_best = 84\n",
    "# selectKBest = SelectKBest(chi2, k_best)\n",
    "# selectKBest.fit(train_features, train_labels)\n",
    "# best_train_features = selectKBest.transform(train_features)\n",
    "\n",
    "# idxs_selected = selectKBest.get_support(indices=True)\n",
    "# best_train_features = train_features.iloc[:,idxs_selected]\n",
    "\n",
    "# print(best_train_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# new_corr_matrix = best_train_features.corr()\n",
    "# ax = sns.heatmap(new_corr_matrix, square=True, cmap='Purples', ax=ax)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_variance = 0.95 \n",
    "\n",
    "# pca = PCA(pca_variance)\n",
    "# pca.fit(train_features)\n",
    "# best_train_features = pca.transform(train_features)\n",
    "# best_train_features = pd.DataFrame(best_train_features)\n",
    "\n",
    "# print(f'Number of components {pca.n_components_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = 2500\n",
    "\n",
    "# idxs_pos = train_labels[train_labels==1].index\n",
    "# idxs_neg = train_labels[train_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "# idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "# best_train_features_balanced = best_train_features.loc[idxs_balanced]\n",
    "# train_labels_balanced = train_labels.loc[idxs_balanced]\n",
    "# print(f'Proportion balanced: {int(number_samples/1000)}/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from boruta import boruta_py\n",
    "\n",
    "# # define random forest classifier, with utilising all cores and\n",
    "# # sampling in proportion to y labels\n",
    "# forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# # define Boruta feature selection method\n",
    "# feat_selector = boruta_py.BorutaPy(forest, n_estimators='auto', verbose=2, random_state=123)\n",
    "\n",
    "# # find all relevant features\n",
    "# feat_selector.fit(train_features.values, train_labels.values)\n",
    "\n",
    "# # check selected features\n",
    "# print(feat_selector.support_)\n",
    "\n",
    "# # check ranking of features\n",
    "# print(feat_selector.ranking_)\n",
    "\n",
    "# # # call transform() on X to filter it down to selected features\n",
    "# # X_filtered = feat_selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "# [ True False False False False False False  True  True  True  True  True\n",
    "#   True  True  True False  True  True False False  True  True  True  True\n",
    "#   True  True  True False False False  True False  True  True  True  True\n",
    "#  False False  True  True  True  True  True  True  True  True  True  True\n",
    "#  False False False False  True  True  True  True  True  True  True  True\n",
    "#   True  True  True  True  True  True False  True  True  True  True  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True  True\n",
    "#   True False False False  True False False False  True False  True  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True  True\n",
    "#   True False False  True False  True  True  True  True  True  True  True\n",
    "#   True  True False False  True  True  True False False False False  True\n",
    "#   True  True  True  True False  True False False False False  True  True\n",
    "#  False  True  True  True  True False  True  True False False False  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True False\n",
    "#  False False]\n",
    "# [ 1 20 22 42 21 23 28  1  1  1  1  1  1  1  1 13  1  1  7 30  1  1  1  1\n",
    "#   1  1  1 43 25 27  1  3  1  1  1  1  3  2  1  1  1  1  1  1  1  1  1  1\n",
    "#   5  3 24 31  1  1  1  1  1  1  1  1  1  1  1  1  1  1 11  1  1  1  1  1\n",
    "#   1  1  1  1  1  1  1  1  1  1  1  1  1 11 15 16  1 19  2 36  1 44  1  1\n",
    "#   1  1  1  1  1  1  1  1  1  1  1  1  1 34  8  1 11  1  1  1  1  1  1  1\n",
    "#   1  1 39  5  1  1  1 17  9 25 14  1  1  1  1  1 17  1 37 29 41 39  1  1\n",
    "#   2  1  1  1  1  2  1  1  2 35 32  1  1  1  1  1  1  1  1  1  1  1  1  2\n",
    "#  38 32]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
