{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from boruta import boruta_py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of nulls on pandas dataframe\n",
    "def val_pd_df_nan(df):\n",
    "    flat_data = df.values.flatten()\n",
    "    count=0\n",
    "    for value in flat_data:\n",
    "        if value is not None:\n",
    "            continue\n",
    "        count+= 1\n",
    "    return round(100*count/len(flat_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The training set contains 60000 examples in total in which 59000 belong to the negative class and 1000 positive class. The test set contains 16000 examples. There are 171 attributes per record.\n",
    "\n",
    "The attribute names of the data have been anonymized for proprietary reasons. It consists of both single numerical counters and histograms consisting of bins with different conditions. Typically the histograms have open-ended conditions at each end. For example, if we measuring the ambient temperature \"T\" then the histogram could be defined with 4 bins where:\n",
    "\n",
    "The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like \"Identifier_Bin\". In total there are 171 attributes, of which 7 are histogram variables. Missing values are denoted by \"na\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (16000,)\n",
      "(60000, 170) (16000, 170)\n"
     ]
    }
   ],
   "source": [
    "train_ds = pd.read_csv('data/aps_failure_training_set_processed_8bit.csv', na_values='na')\n",
    "test_ds =  pd.read_csv('data/aps_failure_test_set_processed_8bit.csv', na_values='na')\n",
    "\n",
    "train_labels = train_ds['class']\n",
    "test_labels = test_ds['class']\n",
    "train_features = train_ds.drop('class', axis=1)\n",
    "test_features = test_ds.drop('class', axis=1)\n",
    "\n",
    "print(train_labels.shape, test_labels.shape)\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.085938</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>-0.164062</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.039062</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.390625</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.359375</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>-0.085938</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.101562</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.085938</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.101562</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          class    aa_000    ab_000    ac_000    ad_000    ae_000    af_000  \\\n",
       "0     -0.992188  0.117188 -0.289062  0.992188 -0.007812 -0.046875 -0.054688   \n",
       "1     -0.992188 -0.179688 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "2     -0.992188 -0.125000 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "3     -0.992188 -0.406250 -0.289062 -0.468750 -0.007812 -0.046875 -0.007812   \n",
       "4     -0.992188  0.007812 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "59995 -0.992188  0.640625  0.007812 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "59996 -0.992188 -0.390625 -0.289062  0.992188 -0.007812 -0.046875 -0.054688   \n",
       "59997 -0.992188 -0.406250 -0.289062  0.992188 -0.007812 -0.046875 -0.054688   \n",
       "59998 -0.992188  0.140625  0.304688  0.992188 -0.007812 -0.046875 -0.054688   \n",
       "59999 -0.992188 -0.132812  0.281250 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "\n",
       "         ag_000   ag_001    ag_002  ...    ee_002    ee_003    ee_004  \\\n",
       "0     -0.007812 -0.03125 -0.054688  ...  0.687500  0.515625  0.234375   \n",
       "1     -0.007812 -0.03125 -0.054688  ... -0.023438 -0.062500 -0.132812   \n",
       "2     -0.007812 -0.03125 -0.054688  ... -0.140625 -0.093750 -0.015625   \n",
       "3     -0.007812 -0.03125 -0.054688  ... -0.382812 -0.382812 -0.375000   \n",
       "4     -0.007812 -0.03125 -0.054688  ...  0.156250  0.031250 -0.031250   \n",
       "...         ...      ...       ...  ...       ...       ...       ...   \n",
       "59995 -0.007812 -0.03125 -0.054688  ...  0.476562  0.656250  0.718750   \n",
       "59996 -0.007812 -0.03125 -0.054688  ... -0.375000 -0.375000 -0.359375   \n",
       "59997 -0.007812 -0.03125 -0.054688  ... -0.382812 -0.382812 -0.375000   \n",
       "59998 -0.007812 -0.03125 -0.054688  ...  0.218750  0.023438 -0.085938   \n",
       "59999 -0.007812 -0.03125 -0.054688  ... -0.007812 -0.046875 -0.085938   \n",
       "\n",
       "         ee_005    ee_006    ee_007    ee_008    ee_009    ef_000    eg_000  \n",
       "0      0.070312  0.007812 -0.109375 -0.140625 -0.171875 -0.023438 -0.023438  \n",
       "1     -0.132812 -0.187500 -0.148438 -0.085938 -0.140625 -0.023438 -0.023438  \n",
       "2      0.015625 -0.007812 -0.109375 -0.093750 -0.164062 -0.023438 -0.023438  \n",
       "3     -0.351562 -0.312500 -0.195312 -0.304688 -0.171875  0.890625  0.992188  \n",
       "4     -0.039062 -0.046875 -0.015625  0.656250 -0.148438 -0.023438 -0.023438  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "59995  0.734375  0.640625  0.218750  0.992188  0.421875 -0.023438 -0.023438  \n",
       "59996 -0.289062 -0.312500 -0.195312 -0.304688 -0.171875 -0.023438 -0.023438  \n",
       "59997 -0.351562 -0.312500 -0.195312 -0.304688 -0.171875 -0.023438 -0.023438  \n",
       "59998 -0.148438 -0.132812 -0.101562  0.992188  0.992188 -0.023438 -0.023438  \n",
       "59999 -0.125000 -0.101562 -0.109375  0.070312 -0.171875 -0.023438 -0.023438  \n",
       "\n",
       "[60000 rows x 171 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% of train data are non-valid.\n",
      "0% of test data are non-valid.\n"
     ]
    }
   ],
   "source": [
    "print(f'{val_pd_df_nan(train_features)}% of train data are non-valid.')\n",
    "print(f'{val_pd_df_nan(test_features)}% of test data are non-valid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_features)\n",
    "\n",
    "train_features = pd.DataFrame(scaler.transform(train_features), columns=train_features.columns)\n",
    "test_features = pd.DataFrame(scaler.transform(test_features), columns=test_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(round)\n",
    "train_labels = train_labels.replace({-1:0})\n",
    "\n",
    "test_labels = test_labels.apply(round)\n",
    "test_labels = test_labels.replace({-1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59000\n",
      "1     1000\n",
      "Name: class, dtype: int64\n",
      "0    15625\n",
      "1      375\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.value_counts())\n",
    "print(test_labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# corr_matrix = train_features.corr()\n",
    "# ax = sns.heatmap(corr_matrix, square=True, cmap='Purples', ax=ax)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_best = 84\n",
    "# selectKBest = SelectKBest(chi2, k_best)\n",
    "# selectKBest.fit(train_features, train_labels)\n",
    "# best_train_features = selectKBest.transform(train_features)\n",
    "\n",
    "# idxs_selected = selectKBest.get_support(indices=True)\n",
    "# best_train_features = train_features.iloc[:,idxs_selected]\n",
    "\n",
    "# print(best_train_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# new_corr_matrix = best_train_features.corr()\n",
    "# ax = sns.heatmap(new_corr_matrix, square=True, cmap='Purples', ax=ax)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_variance = 0.95 \n",
    "\n",
    "# pca = PCA(pca_variance)\n",
    "# pca.fit(train_features)\n",
    "# best_train_features = pca.transform(train_features)\n",
    "# best_train_features = pd.DataFrame(best_train_features)\n",
    "\n",
    "# print(f'Number of components {pca.n_components_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_samples = 2500\n",
    "\n",
    "# idxs_pos = train_labels[train_labels==1].index\n",
    "# idxs_neg = train_labels[train_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "# idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "# best_train_features_balanced = best_train_features.loc[idxs_balanced]\n",
    "# train_labels_balanced = train_labels.loc[idxs_balanced]\n",
    "# print(f'Proportion balanced: {int(number_samples/1000)}/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from boruta import boruta_py\n",
    "\n",
    "# # define random forest classifier, with utilising all cores and\n",
    "# # sampling in proportion to y labels\n",
    "# forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# # define Boruta feature selection method\n",
    "# feat_selector = boruta_py.BorutaPy(forest, n_estimators='auto', verbose=2, random_state=123)\n",
    "\n",
    "# # find all relevant features\n",
    "# feat_selector.fit(train_features.values, train_labels.values)\n",
    "\n",
    "# # check selected features\n",
    "# print(feat_selector.support_)\n",
    "\n",
    "# # check ranking of features\n",
    "# print(feat_selector.ranking_)\n",
    "\n",
    "# # # call transform() on X to filter it down to selected features\n",
    "# # X_filtered = feat_selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "# [ True False False False False False False  True  True  True  True  True\n",
    "#   True  True  True False  True  True False False  True  True  True  True\n",
    "#   True  True  True False False False  True False  True  True  True  True\n",
    "#  False False  True  True  True  True  True  True  True  True  True  True\n",
    "#  False False False False  True  True  True  True  True  True  True  True\n",
    "#   True  True  True  True  True  True False  True  True  True  True  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True  True\n",
    "#   True False False False  True False False False  True False  True  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True  True\n",
    "#   True False False  True False  True  True  True  True  True  True  True\n",
    "#   True  True False False  True  True  True False False False False  True\n",
    "#   True  True  True  True False  True False False False False  True  True\n",
    "#  False  True  True  True  True False  True  True False False False  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True False\n",
    "#  False False]\n",
    "# [ 1 20 22 42 21 23 28  1  1  1  1  1  1  1  1 13  1  1  7 30  1  1  1  1\n",
    "#   1  1  1 43 25 27  1  3  1  1  1  1  3  2  1  1  1  1  1  1  1  1  1  1\n",
    "#   5  3 24 31  1  1  1  1  1  1  1  1  1  1  1  1  1  1 11  1  1  1  1  1\n",
    "#   1  1  1  1  1  1  1  1  1  1  1  1  1 11 15 16  1 19  2 36  1 44  1  1\n",
    "#   1  1  1  1  1  1  1  1  1  1  1  1  1 34  8  1 11  1  1  1  1  1  1  1\n",
    "#   1  1 39  5  1  1  1 17  9 25 14  1  1  1  1  1 17  1 37 29 41 39  1  1\n",
    "#   2  1  1  1  1  2  1  1  2 35 32  1  1  1  1  1  1  1  1  1  1  1  1  2\n",
    "#  38 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectKBest = SelectKBest(chi2, 84)\n",
    "\n",
    "pca = PCA(0.95)\n",
    "\n",
    "borutaSelector = boruta_py.BorutaPy(\n",
    "    RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5), \n",
    "    n_estimators='auto', \n",
    "    verbose=0, \n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# estimators pipeline\n",
    "kbest_pipeline = Pipeline([('selectKBest', selectKBest), ('rf', rf)])\n",
    "pca_pipeline = Pipeline([('pca', pca), ('rf', rf)])\n",
    "boruta_pipeline = Pipeline([('borutaSelector', borutaSelector), ('rf', rf)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     15625\n",
      "           1       0.37      0.96      0.53       375\n",
      "\n",
      "    accuracy                           0.96     16000\n",
      "   macro avg       0.68      0.96      0.76     16000\n",
      "weighted avg       0.98      0.96      0.97     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kbest_pipeline.fit(train_features, train_labels)\n",
    "y_pred = kbest_pipeline.predict(test_features)\n",
    "report = classification_report(test_labels, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     15625\n",
      "           1       0.29      0.97      0.45       375\n",
      "\n",
      "    accuracy                           0.94     16000\n",
      "   macro avg       0.65      0.96      0.71     16000\n",
      "weighted avg       0.98      0.94      0.96     16000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_pipeline.fit(train_features, train_labels)\n",
    "y_pred = pca_pipeline.predict(test_features)\n",
    "report = classification_report(test_labels, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "boruta_pipeline.fit(train_features.values, train_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pca_pipeline.predict(test_features)\n",
    "report = classification_report(test_labels, y_pred)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
