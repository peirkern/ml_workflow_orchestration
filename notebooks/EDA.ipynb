{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "from boruta import boruta_py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the percentage of nulls on pandas dataframe\n",
    "def val_pd_df_nan(df):\n",
    "    flat_data = df.values.flatten()\n",
    "    count=0\n",
    "    for value in flat_data:\n",
    "        if value is not None:\n",
    "            continue\n",
    "        count+= 1\n",
    "    return round(100*count/len(flat_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "The training set contains 60000 examples in total in which 59000 belong to the negative class and 1000 positive class. The test set contains 16000 examples. There are 171 attributes per record.\n",
    "\n",
    "The attribute names of the data have been anonymized for proprietary reasons. It consists of both single numerical counters and histograms consisting of bins with different conditions. Typically the histograms have open-ended conditions at each end. For example, if we measuring the ambient temperature \"T\" then the histogram could be defined with 4 bins where:\n",
    "\n",
    "The attributes are as follows: class, then anonymized operational data. The operational data have an identifier and a bin id, like \"Identifier_Bin\". In total there are 171 attributes, of which 7 are histogram variables. Missing values are denoted by \"na\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,) (16000,)\n",
      "(60000, 170) (16000, 170)\n"
     ]
    }
   ],
   "source": [
    "train_ds = pd.read_csv('data/aps_failure_training_set_processed_8bit.csv', na_values='na')\n",
    "test_ds =  pd.read_csv('data/aps_failure_test_set_processed_8bit.csv', na_values='na')\n",
    "\n",
    "train_labels = train_ds['class']\n",
    "test_labels = test_ds['class']\n",
    "train_features = train_ds.drop('class', axis=1)\n",
    "test_features = test_ds.drop('class', axis=1)\n",
    "\n",
    "print(train_labels.shape, test_labels.shape)\n",
    "print(train_features.shape, test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.187500</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.085938</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>-0.164062</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.992188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.039062</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.640625</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.390625</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.359375</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.304688</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>-0.085938</td>\n",
       "      <td>-0.148438</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.101562</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>-0.992188</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.03125</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.085938</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>-0.101562</td>\n",
       "      <td>-0.109375</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          class    aa_000    ab_000    ac_000    ad_000    ae_000    af_000  \\\n",
       "0     -0.992188  0.117188 -0.289062  0.992188 -0.007812 -0.046875 -0.054688   \n",
       "1     -0.992188 -0.179688 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "2     -0.992188 -0.125000 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "3     -0.992188 -0.406250 -0.289062 -0.468750 -0.007812 -0.046875 -0.007812   \n",
       "4     -0.992188  0.007812 -0.289062 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "59995 -0.992188  0.640625  0.007812 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "59996 -0.992188 -0.390625 -0.289062  0.992188 -0.007812 -0.046875 -0.054688   \n",
       "59997 -0.992188 -0.406250 -0.289062  0.992188 -0.007812 -0.046875 -0.054688   \n",
       "59998 -0.992188  0.140625  0.304688  0.992188 -0.007812 -0.046875 -0.054688   \n",
       "59999 -0.992188 -0.132812  0.281250 -0.468750 -0.007812 -0.046875 -0.054688   \n",
       "\n",
       "         ag_000   ag_001    ag_002  ...    ee_002    ee_003    ee_004  \\\n",
       "0     -0.007812 -0.03125 -0.054688  ...  0.687500  0.515625  0.234375   \n",
       "1     -0.007812 -0.03125 -0.054688  ... -0.023438 -0.062500 -0.132812   \n",
       "2     -0.007812 -0.03125 -0.054688  ... -0.140625 -0.093750 -0.015625   \n",
       "3     -0.007812 -0.03125 -0.054688  ... -0.382812 -0.382812 -0.375000   \n",
       "4     -0.007812 -0.03125 -0.054688  ...  0.156250  0.031250 -0.031250   \n",
       "...         ...      ...       ...  ...       ...       ...       ...   \n",
       "59995 -0.007812 -0.03125 -0.054688  ...  0.476562  0.656250  0.718750   \n",
       "59996 -0.007812 -0.03125 -0.054688  ... -0.375000 -0.375000 -0.359375   \n",
       "59997 -0.007812 -0.03125 -0.054688  ... -0.382812 -0.382812 -0.375000   \n",
       "59998 -0.007812 -0.03125 -0.054688  ...  0.218750  0.023438 -0.085938   \n",
       "59999 -0.007812 -0.03125 -0.054688  ... -0.007812 -0.046875 -0.085938   \n",
       "\n",
       "         ee_005    ee_006    ee_007    ee_008    ee_009    ef_000    eg_000  \n",
       "0      0.070312  0.007812 -0.109375 -0.140625 -0.171875 -0.023438 -0.023438  \n",
       "1     -0.132812 -0.187500 -0.148438 -0.085938 -0.140625 -0.023438 -0.023438  \n",
       "2      0.015625 -0.007812 -0.109375 -0.093750 -0.164062 -0.023438 -0.023438  \n",
       "3     -0.351562 -0.312500 -0.195312 -0.304688 -0.171875  0.890625  0.992188  \n",
       "4     -0.039062 -0.046875 -0.015625  0.656250 -0.148438 -0.023438 -0.023438  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "59995  0.734375  0.640625  0.218750  0.992188  0.421875 -0.023438 -0.023438  \n",
       "59996 -0.289062 -0.312500 -0.195312 -0.304688 -0.171875 -0.023438 -0.023438  \n",
       "59997 -0.351562 -0.312500 -0.195312 -0.304688 -0.171875 -0.023438 -0.023438  \n",
       "59998 -0.148438 -0.132812 -0.101562  0.992188  0.992188 -0.023438 -0.023438  \n",
       "59999 -0.125000 -0.101562 -0.109375  0.070312 -0.171875 -0.023438 -0.023438  \n",
       "\n",
       "[60000 rows x 171 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% of train data are non-valid.\n",
      "0% of test data are non-valid.\n"
     ]
    }
   ],
   "source": [
    "print(f'{val_pd_df_nan(train_features)}% of train data are non-valid.')\n",
    "print(f'{val_pd_df_nan(test_features)}% of test data are non-valid.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_features)\n",
    "\n",
    "train_features = pd.DataFrame(scaler.transform(train_features), columns=train_features.columns)\n",
    "test_features = pd.DataFrame(scaler.transform(test_features), columns=test_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(round)\n",
    "train_labels = train_labels.replace({-1:0})\n",
    "\n",
    "test_labels = test_labels.apply(round)\n",
    "test_labels = test_labels.replace({-1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59000\n",
      "1     1000\n",
      "Name: class, dtype: int64\n",
      "0    15625\n",
      "1      375\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_labels.value_counts())\n",
    "print(test_labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# corr_matrix = train_features.corr()\n",
    "# ax = sns.heatmap(corr_matrix, square=True, cmap='Purples', ax=ax)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_best = 84\n",
    "# selectKBest = SelectKBest(chi2, k_best)\n",
    "# selectKBest.fit(train_features, train_labels)\n",
    "# best_train_features = selectKBest.transform(train_features)\n",
    "\n",
    "# idxs_selected = selectKBest.get_support(indices=True)\n",
    "# best_train_features = train_features.iloc[:,idxs_selected]\n",
    "\n",
    "# print(best_train_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(10,10))\n",
    "# new_corr_matrix = best_train_features.corr()\n",
    "# ax = sns.heatmap(new_corr_matrix, square=True, cmap='Purples', ax=ax)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_variance = 0.95 \n",
    "\n",
    "# pca = PCA(pca_variance)\n",
    "# pca.fit(train_features)\n",
    "# best_train_features = pca.transform(train_features)\n",
    "# best_train_features = pd.DataFrame(best_train_features)\n",
    "\n",
    "# print(f'Number of components {pca.n_components_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion balanced: 1/1\n",
      "1    1000\n",
      "0    1000\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "number_samples = 1000\n",
    "\n",
    "idxs_pos = train_labels[train_labels==1].index\n",
    "idxs_neg = train_labels[train_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "train_features_balanced = train_features.loc[idxs_balanced]\n",
    "train_labels_balanced = train_labels.loc[idxs_balanced]\n",
    "print(f'Proportion balanced: {int(number_samples/1000)}/1')\n",
    "print(train_labels_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion balanced: 0/1\n",
      "1    375\n",
      "0    375\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "number_samples = 375\n",
    "\n",
    "idxs_pos = test_labels[test_labels==1].index\n",
    "idxs_neg = test_labels[test_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "test_features_balanced = test_features.loc[idxs_balanced]\n",
    "test_labels_balanced = test_labels.loc[idxs_balanced]\n",
    "print(f'Proportion balanced: {int(number_samples/1000)}/1')\n",
    "print(test_labels_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection with Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from boruta import boruta_py\n",
    "\n",
    "# # define random forest classifier, with utilising all cores and\n",
    "# # sampling in proportion to y labels\n",
    "# forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# # define Boruta feature selection method\n",
    "# feat_selector = boruta_py.BorutaPy(forest, n_estimators='auto', verbose=2, random_state=123)\n",
    "\n",
    "# # find all relevant features\n",
    "# feat_selector.fit(train_features.values, train_labels.values)\n",
    "\n",
    "# # check selected features\n",
    "# print(feat_selector.support_)\n",
    "\n",
    "# # check ranking of features\n",
    "# print(feat_selector.ranking_)\n",
    "\n",
    "# # # call transform() on X to filter it down to selected features\n",
    "# # X_filtered = feat_selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "# [ True False False False False False False  True  True  True  True  True\n",
    "#   True  True  True False  True  True False False  True  True  True  True\n",
    "#   True  True  True False False False  True False  True  True  True  True\n",
    "#  False False  True  True  True  True  True  True  True  True  True  True\n",
    "#  False False False False  True  True  True  True  True  True  True  True\n",
    "#   True  True  True  True  True  True False  True  True  True  True  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True  True\n",
    "#   True False False False  True False False False  True False  True  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True  True\n",
    "#   True False False  True False  True  True  True  True  True  True  True\n",
    "#   True  True False False  True  True  True False False False False  True\n",
    "#   True  True  True  True False  True False False False False  True  True\n",
    "#  False  True  True  True  True False  True  True False False False  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True False\n",
    "#  False False]\n",
    "# [ 1 20 22 42 21 23 28  1  1  1  1  1  1  1  1 13  1  1  7 30  1  1  1  1\n",
    "#   1  1  1 43 25 27  1  3  1  1  1  1  3  2  1  1  1  1  1  1  1  1  1  1\n",
    "#   5  3 24 31  1  1  1  1  1  1  1  1  1  1  1  1  1  1 11  1  1  1  1  1\n",
    "#   1  1  1  1  1  1  1  1  1  1  1  1  1 11 15 16  1 19  2 36  1 44  1  1\n",
    "#   1  1  1  1  1  1  1  1  1  1  1  1  1 34  8  1 11  1  1  1  1  1  1  1\n",
    "#   1  1 39  5  1  1  1 17  9 25 14  1  1  1  1  1 17  1 37 29 41 39  1  1\n",
    "#   2  1  1  1  1  2  1  1  2 35 32  1  1  1  1  1  1  1  1  1  1  1  1  2\n",
    "#  38 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectKBest = SelectKBest(chi2, 84)\n",
    "\n",
    "pca = PCA(0.95)\n",
    "\n",
    "borutaSelector = boruta_py.BorutaPy(\n",
    "    RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5), \n",
    "    n_estimators='auto', \n",
    "    verbose=0, \n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# estimators pipeline\n",
    "rf_pipeline = Pipeline([('rf', rf)])\n",
    "kbest_pipeline = Pipeline([('selectKBest', selectKBest), ('rf', rf)])\n",
    "pca_pipeline = Pipeline([('pca', pca), ('rf', rf)])\n",
    "boruta_pipeline = Pipeline([('borutaSelector', borutaSelector), ('rf', rf)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KBest + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       375\n",
      "           1       0.94      0.98      0.96       375\n",
      "\n",
      "    accuracy                           0.95       750\n",
      "   macro avg       0.96      0.95      0.95       750\n",
      "weighted avg       0.96      0.95      0.95       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kbest_pipeline.fit(train_features_balanced, train_labels_balanced)\n",
    "y_pred = kbest_pipeline.predict(test_features_balanced)\n",
    "report = classification_report(test_labels_balanced, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       375\n",
      "           1       0.90      0.99      0.94       375\n",
      "\n",
      "    accuracy                           0.94       750\n",
      "   macro avg       0.94      0.94      0.94       750\n",
      "weighted avg       0.94      0.94      0.94       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_pipeline.fit(train_features_balanced, train_labels_balanced)\n",
    "y_pred = pca_pipeline.predict(test_features_balanced)\n",
    "report = classification_report(test_labels_balanced, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boruta + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       375\n",
      "           1       0.94      0.98      0.96       375\n",
      "\n",
      "    accuracy                           0.96       750\n",
      "   macro avg       0.96      0.96      0.96       750\n",
      "weighted avg       0.96      0.96      0.96       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "boruta_pipeline.fit(train_features_balanced.values, train_labels_balanced.values)\n",
    "y_pred = boruta_pipeline.predict(test_features_balanced.values)\n",
    "report = classification_report(test_labels_balanced, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(slice(None, None, None), array([ True, False, False, False, False, False, False,  True,  True,\n        True,  True,  True,  True, False, False, False,  True,  True,\n       False, False,  True,  True,  True,  True,  True,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False,  True,  True,  True, False,  True,  True,  True,\n       False, False,  True, False, False, False, False,  True,  True,\n        True,  True,  True,  True, False, False,  True,  True,  True,\n        True,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False, False, False,  True, False,\n       False, False,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True, False, False,  True, False,  True,  True,  True,  True,\n        True,  True, False, False, False, False, False, False, False,\n        True, False, False, False, False,  True,  True,  True, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False,  True,  True, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False, False, False, False]))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-19232e7032ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features_balanced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels_balanced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboruta_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features_balanced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels_balanced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, weak)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweak\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweak\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\boruta\\boruta_py.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, weak)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_weak_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2994\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2995\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 )\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), array([ True, False, False, False, False, False, False,  True,  True,\n        True,  True,  True,  True, False, False, False,  True,  True,\n       False, False,  True,  True,  True,  True,  True,  True, False,\n       False, False, False, False, False, False, False, False, False,\n       False, False,  True,  True,  True, False,  True,  True,  True,\n       False, False,  True, False, False, False, False,  True,  True,\n        True,  True,  True,  True, False, False,  True,  True,  True,\n        True,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False, False, False,  True, False,\n       False, False,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True, False, False,  True, False,  True,  True,  True,  True,\n        True,  True, False, False, False, False, False, False, False,\n        True, False, False, False, False,  True,  True,  True, False,\n       False, False, False, False, False, False, False,  True, False,\n       False, False, False,  True,  True, False, False, False, False,\n       False, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True, False, False, False, False]))' is an invalid key"
     ]
    }
   ],
   "source": [
    "rf.fit(train_features_balanced, train_labels_balanced)\n",
    "y_pred = boruta_pipeline.predict(test_features_balanced)\n",
    "report = classification_report(test_labels_balanced, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
